{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938fb092-0639-4321-9e33-a8bc8ff8234c",
   "metadata": {},
   "source": [
    "# Load Libraries and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcb50b5-3c4e-44a8-adad-fa94ff7aa4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from tqdm import trange\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "\n",
    "from self_attention_cv.Transformer3Dsegmentation.tranf3Dseg import Transformer3dSeg\n",
    "from self_attention_cv.transunet import TransUnet\n",
    "from self_attention_cv import TransformerEncoder\n",
    "from self_attention_cv import ViT, ResNet50ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133eaa9e-a422-4706-97d1-18fb16df1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y.astype(np.int16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceda36f1-4fa6-4c15-8969-9696bfb6066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brats_batch(prefix, \n",
    "                         contrasts, \n",
    "                         batch_size=32, \n",
    "                         tumour='*', \n",
    "                         patient_ids='*',\n",
    "                         augment_size=None,\n",
    "                         infinite=True):\n",
    "    \"\"\"\n",
    "    Generate arrays for each batch, for x (data) and y (labels), where the contrast is treated like a colour channel.\n",
    "    \n",
    "    Example:\n",
    "    x_batch shape: (32, 240, 240, 155, 4)\n",
    "    y_batch shape: (32, 240, 240, 155)\n",
    "    \n",
    "    augment_size must be less than or equal to the batch_size, if None will not augment.\n",
    "    \n",
    "    \"\"\"\n",
    "    file_pattern = '{prefix}/MICCAI_BraTS_2018_Data_Training/{tumour}/{patient_id}/{patient_id}_{contrast}.nii.gz'\n",
    "    while True:\n",
    "        n_classes = 4\n",
    "\n",
    "        # get list of filenames for every contrast available\n",
    "        keys = dict(prefix=prefix, tumour=tumour)\n",
    "        filenames_by_contrast = {}\n",
    "        for contrast in contrasts:\n",
    "            filenames_by_contrast[contrast] = glob.glob(file_pattern.format(contrast=contrast, patient_id=patient_ids, **keys)) if patient_ids == '*' else []\n",
    "            if patient_ids != '*':\n",
    "                contrast_files = []\n",
    "                for patient_id in patient_ids:\n",
    "                    contrast_files.extend(glob.glob(file_pattern.format(contrast=contrast, patient_id=patient_id, **keys)))\n",
    "                filenames_by_contrast[contrast] = contrast_files\n",
    "\n",
    "        # get the shape of one 3D volume and initialize the batch lists\n",
    "        arbitrary_contrast = contrasts[0]\n",
    "        shape = nib.load(filenames_by_contrast[arbitrary_contrast][0]).get_fdata().shape\n",
    "\n",
    "        # initialize empty array of batches\n",
    "        x_batch = np.empty((batch_size, ) + shape + (len(contrasts), )) #, dtype=np.int32)\n",
    "        y_batch = np.empty((batch_size, ) + shape + (n_classes,)) #, dtype=np.int32)\n",
    "        num_images = len(filenames_by_contrast[arbitrary_contrast])\n",
    "        np.random.shuffle(filenames_by_contrast[arbitrary_contrast])\n",
    "        for bindex in trange(0, num_images, batch_size):\n",
    "            filenames = filenames_by_contrast[arbitrary_contrast][bindex:bindex + batch_size]\n",
    "            for findex, filename in enumerate(filenames):\n",
    "                for cindex, contrast in enumerate(contrasts):\n",
    "\n",
    "                    # load raw image batches and normalize the pixels\n",
    "                    tmp_img = nib.load(filename.replace(arbitrary_contrast, contrast)).get_fdata()\n",
    "                    tmp_img = scalar.fit_transform(tmp_img.reshape(-1, tmp_img.shape[-1])).reshape(tmp_img.shape)\n",
    "                    x_batch[findex, ..., cindex] = tmp_img\n",
    "\n",
    "                    # load mask batches and change to categorical\n",
    "                    tmp_mask = nib.load(filename.replace(arbitrary_contrast, 'seg')).get_fdata()\n",
    "                    tmp_mask[tmp_mask==4] = 3\n",
    "                    tmp_mask = to_categorical(tmp_mask, num_classes = 4)\n",
    "                    y_batch[findex] = tmp_mask\n",
    "\n",
    "            if bindex + batch_size > num_images:\n",
    "                x_batch, y_batch = x_batch[:num_images - bindex], y_batch[:num_images - bindex]\n",
    "            if augment_size is not None:\n",
    "                # x_aug, y_aug = augment(x_batch, y_batch, augment_size)\n",
    "                x_aug = None\n",
    "                y_aug = None\n",
    "                yield np.append(x_batch, x_aug), np.append(y_batch, y_aug)\n",
    "            else:\n",
    "                yield x_batch, y_batch\n",
    "        if not infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3595d619-a8bc-4ea6-a5de-10efe4978352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = '/home/atom/Documents/datasets/brats' # Adam's Station\n",
    "prefix = '/Users/Atom/Documents/datasets/brats'\n",
    "trained_model = 'transformer_models/model_20220410_001231_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "992ce1df-c983-4e61-845b-d16bd1493a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_classes = 4\n",
    "brats_contrasts = 4\n",
    "brats_x = 240\n",
    "brats_y = 240\n",
    "brats_z = 155\n",
    "\n",
    "block_side = 48 # 24 # W in the paper\n",
    "patch_side = 16 # 8 # w in the paper, so n = W/w = 3, N = 27\n",
    "embedding_size = 2048 # 1024 # D\n",
    "transformer_blocks = 5 # K\n",
    "msa_heads = 5\n",
    "mlp_size = 1024 # 2048 # 1024\n",
    "\n",
    "dropout = 0.15\n",
    "max_epochs = 50\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facf80e7-4b96-449b-b01a-20280d0f0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer3dSeg(subvol_dim=block_side, \n",
    "                         patch_dim=patch_side, \n",
    "                         num_classes=brats_classes,\n",
    "                         in_channels=brats_contrasts,\n",
    "                         dim=embedding_size,\n",
    "                         blocks=transformer_blocks, \n",
    "                         heads=msa_heads, \n",
    "                         dim_linear_block=mlp_size,\n",
    "                         dropout=dropout) #, transformer=TransformerEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1924979-bb58-4841-b341-0988dc17605b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Transformer3dSeg:\n\tsize mismatch for project_patches.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 16384]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrained_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/.miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1478\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1479\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1483\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer3dSeg:\n\tsize mismatch for project_patches.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 16384])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'{prefix}/{trained_model}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8e85e3-c8be-4186-9b82-a625f96d1c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer3dSeg(\n",
       "  (project_patches): Linear(in_features=16384, out_features=2048, bias=True)\n",
       "  (emb_dropout): Dropout(p=0.15, inplace=False)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (to_qvk): Linear(in_features=2048, out_features=6135, bias=False)\n",
       "          (W_0): Linear(in_features=2045, out_features=2048, bias=False)\n",
       "        )\n",
       "        (drop): Dropout(p=0.15, inplace=False)\n",
       "        (norm_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (4): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (to_qvk): Linear(in_features=2048, out_features=6135, bias=False)\n",
       "          (W_0): Linear(in_features=2045, out_features=2048, bias=False)\n",
       "        )\n",
       "        (drop): Dropout(p=0.15, inplace=False)\n",
       "        (norm_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (4): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (to_qvk): Linear(in_features=2048, out_features=6135, bias=False)\n",
       "          (W_0): Linear(in_features=2045, out_features=2048, bias=False)\n",
       "        )\n",
       "        (drop): Dropout(p=0.15, inplace=False)\n",
       "        (norm_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (4): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (to_qvk): Linear(in_features=2048, out_features=6135, bias=False)\n",
       "          (W_0): Linear(in_features=2045, out_features=2048, bias=False)\n",
       "        )\n",
       "        (drop): Dropout(p=0.15, inplace=False)\n",
       "        (norm_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (4): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (to_qvk): Linear(in_features=2048, out_features=6135, bias=False)\n",
       "          (W_0): Linear(in_features=2045, out_features=2048, bias=False)\n",
       "        )\n",
       "        (drop): Dropout(p=0.15, inplace=False)\n",
       "        (norm_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (4): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_seg_head): Linear(in_features=2048, out_features=108, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eabb26-6d12-4b42-a7c6-ab1f5c943080",
   "metadata": {},
   "source": [
    "# Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df483d64-02f5-43d8-9744-f9913238372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 'Brats18_TCIA01_147_1'\n",
    "tumour = 'HGG'\n",
    "contrast = 'flair'\n",
    "contrasts = ['t1ce', 'flair', 't2', 't1']\n",
    "filename = f'{prefix}/MICCAI_BraTS_2018_Data_Training/{tumour}/{test_id}/{test_id}_{contrast}.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f02569-a348-44f8-ab87-02c3cc8dd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img  = nib.load(filename)\n",
    "nii_data = nii_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc5aa2a-e265-4220-a23d-aab9d6499cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 155)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f82f7396-cd3a-4432-8b19-327524f8c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:23<00:00, 23.32s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, mask in generate_brats_batch(prefix, contrasts, batch_size=1, patient_ids=[test_id], infinite=False):\n",
    "        # img (1, 240, 240, 155, 4) -> (1, 4, 240, 240, 155)\n",
    "        img, mask = np.rollaxis(img, -1, 1), np.rollaxis(mask, -1, 1)\n",
    "        full_output = np.zeros_like(mask)\n",
    "        for i in range(0, brats_x, block_side):\n",
    "            for j in range(0, brats_y, block_side):\n",
    "                for k in range(6, brats_z - block_side, block_side):\n",
    "                    img_block = img[..., i:i+block_side, j:j+block_side, k:k+block_side]\n",
    "                    mask_block = mask[..., i:i+block_side, j:j+block_side, k:k+block_side]\n",
    "                    output = torch.softmax(model(torch.FloatTensor(img_block)), 1)\n",
    "                    full_output[..., i:i+block_side, j:j+block_side, k:k+block_side] = np.repeat(np.repeat(np.repeat(output, patch_side, axis=-3), patch_side, axis=-2), patch_side, axis=-1)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84caf7cf-9a82-42f6-9bcd-56ea000191f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = nib.load(filename.replace(contrast, 'seg')).get_fdata().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13d12-34c7-470d-b415-7ead9de1bcd1",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b8b1a4-ca16-435c-8465-7e558b276d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 240, 240, 155)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4ea67a0-3fab-4587-a043-b497aca7627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(full_output[0, 0, :, :, 75]);\n",
    "plt.colorbar();\n",
    "# plt.hist(full_output[0, 0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1130c4b1-ea7f-436a-ab08-c325b41a8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.view_image(full_output[0, 0], name=\"tumour core prediction probabilities\")\n",
    "for i in range(len(contrasts)):\n",
    "    viewer.add_image(img[0, i, ...], name=test_id + '' + contrasts[i])\n",
    "\n",
    "gt_layer = viewer.add_labels(ground_truth, name=\"ground truth\")\n",
    "pred_layer = viewer.add_labels(full_output.argmax(axis=1)[0], name=\"predicted classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c2be8-e9f8-411a-b39c-f2c1a87c8731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972886ee-4419-40aa-978c-dca014715ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7a621-3605-4985-a370-05b49b08cd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee96468-ba95-4637-a548-3ef52b44f002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3024c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
