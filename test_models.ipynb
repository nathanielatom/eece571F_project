{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938fb092-0639-4321-9e33-a8bc8ff8234c",
   "metadata": {},
   "source": [
    "# Load Libraries and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13a130c-1ad6-4029-8e70-489bc87ceb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 17:27:16.104751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.111089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.111321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.111880: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-02 17:27:16.112385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.112574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.112745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.636080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.636422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.636760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 17:27:16.637077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "my_model = load_model('/home/atom/Documents/datasets/brats/unet_model_20220401.h5', \n",
    "                      compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf064f4-1631-43d9-8423-ec2690b428a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_3D(img, new_size):\n",
    "    img_shape = img.shape\n",
    "    x_mid = int(img_shape[0]/2)\n",
    "    y_mid = int(img_shape[1]/2)\n",
    "    z_mid = int(img_shape[2]/2)\n",
    "\n",
    "    x_diff = int(abs(new_size[0]-x_mid))\n",
    "    y_diff = int(abs(new_size[1]-y_mid))\n",
    "    z_diff = int(abs(new_size[2]-z_mid))\n",
    "\n",
    "    x_start = x_mid-x_diff\n",
    "    y_start = y_mid-y_diff\n",
    "    z_start = z_mid-z_diff\n",
    "\n",
    "    tmp_img = img[x_start:x_start+new_size[0],y_start:y_start+new_size[1],z_start:z_start+new_size[2]]\n",
    "    return tmp_img\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def generate_brats_batch(file_pattern, \n",
    "                         contrasts, \n",
    "                         batch_size=32, \n",
    "                         tumour='*', \n",
    "                         patient_ids='*',\n",
    "                         crop_size = (None,None,None), \n",
    "                         augment_size=None,\n",
    "                         infinite = True):\n",
    "    \"\"\"\n",
    "    Generate arrays for each batch, for x (data) and y (labels), where the contrast is treated like a colour channel.\n",
    "    \n",
    "    Example:\n",
    "    x_batch shape: (32, 240, 240, 155, 4)\n",
    "    y_batch shape: (32, 240, 240, 155)\n",
    "    \n",
    "    augment_size must be less than or equal to the batch_size, if None will not augment.\n",
    "    \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        n_classes = 4\n",
    "\n",
    "        # get list of filenames for every contrast available\n",
    "        keys = dict(prefix=prefix, tumour=tumour)\n",
    "        filenames_by_contrast = {}\n",
    "        for contrast in contrasts:\n",
    "            filenames_by_contrast[contrast] = glob.glob(file_pattern.format(contrast=contrast, patient_id=patient_ids, **keys)) if patient_ids == '*' else []\n",
    "            if patient_ids != '*':\n",
    "                contrast_files = []\n",
    "                for patient_id in patient_ids:\n",
    "                    contrast_files.extend(glob.glob(file_pattern.format(contrast=contrast, patient_id=patient_id, **keys)))\n",
    "                filenames_by_contrast[contrast] = contrast_files\n",
    "\n",
    "        # get the shape of one 3D volume and initialize the batch lists\n",
    "        arbitrary_contrast = contrasts[0]\n",
    "        if crop_size == (None,None,None):\n",
    "            shape = nib.load(filenames_by_contrast[arbitrary_contrast][0]).get_fdata().shape\n",
    "        else:\n",
    "            shape = crop_size\n",
    "\n",
    "        # initialize empty array of batches\n",
    "        x_batch = np.empty((batch_size, ) + shape + (len(contrasts), )) #, dtype=np.int32)\n",
    "        y_batch = np.empty((batch_size, ) + shape + (n_classes,)) #, dtype=np.int32)\n",
    "        num_images = len(filenames_by_contrast[arbitrary_contrast])\n",
    "        np.random.shuffle(filenames_by_contrast[arbitrary_contrast])\n",
    "        for bindex in tqdm(range(0, num_images, batch_size), total=num_images):\n",
    "            filenames = filenames_by_contrast[arbitrary_contrast][bindex:bindex + batch_size]\n",
    "            for findex, filename in enumerate(filenames):\n",
    "                for cindex, contrast in enumerate(contrasts):\n",
    "\n",
    "                    # load raw image batches and normalize the pixels\n",
    "                    tmp_img = nib.load(filename.replace(arbitrary_contrast, contrast)).get_fdata()\n",
    "                    try:\n",
    "                        tmp_img = scaler.fit_transform(tmp_img.reshape(-1, tmp_img.shape[-1])).reshape(tmp_img.shape)\n",
    "                    except:\n",
    "                        print(filename)\n",
    "                        print(contrast)\n",
    "                    x_batch[findex, ..., cindex] = crop_3D(tmp_img, shape)\n",
    "\n",
    "                    # load mask batches and change to categorical\n",
    "                    tmp_mask = nib.load(filename.replace(arbitrary_contrast, 'seg')).get_fdata()\n",
    "                    tmp_mask[tmp_mask==4] = 3\n",
    "                    tmp_mask = crop_3D(tmp_mask, crop_size)\n",
    "                    tmp_mask = to_categorical(tmp_mask, num_classes = 4)\n",
    "                    y_batch[findex] = tmp_mask\n",
    "\n",
    "            if bindex + batch_size > num_images:\n",
    "                x_batch, y_batch = x_batch[:num_images - bindex], y_batch[:num_images - bindex]\n",
    "            if augment_size is not None:\n",
    "                # x_aug, y_aug = augment(x_batch, y_batch, augment_size)\n",
    "                x_aug = None\n",
    "                y_aug = None\n",
    "                yield np.append(x_batch, x_aug), np.append(y_batch, y_aug)\n",
    "            else:\n",
    "                yield x_batch, y_batch\n",
    "        if not infinite:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0545a993-cc4a-4642-9130-6a16301f0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumours = ['LGG','HGG']\n",
    "\n",
    "# prefix = '/Users/jasonfung/Documents/EECE571' # Jason's Macbook\n",
    "# prefix = 'C:/Users/Fungj/Documents/EECE_571F' # Jason's Desktop\n",
    "brats_dir = '/MICCAI_BraTS_2018_Data_Training/'\n",
    "prefix = '/home/atom/Documents/datasets/brats' # Adam's Station\n",
    "file_pattern = '{prefix}/MICCAI_BraTS_2018_Data_Training/{tumour}/{patient_id}/{patient_id}_{contrast}.nii.gz'\n",
    "# patient_id = 'Brats18_TCIA09_620_1'\n",
    "contrasts = ['t1ce', 'flair', 't2']\n",
    "tumours = ['LGG', 'HGG']\n",
    "\n",
    "data_list_LGG = os.listdir(os.path.join(prefix+brats_dir,tumours[0]))\n",
    "data_list_HGG = os.listdir(os.path.join(prefix+brats_dir,tumours[1]))\n",
    "dataset_file_list = data_list_HGG + data_list_LGG\n",
    "\n",
    "# shuffle and split the dataset file list\n",
    "import random\n",
    "random.seed(42)\n",
    "file_list_shuffled = dataset_file_list.copy()\n",
    "random.shuffle(file_list_shuffled)\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_file, test_file = file_list_shuffled[0:int(len(file_list_shuffled)*(1-test_ratio))], file_list_shuffled[int(len(file_list_shuffled)*(1-test_ratio)):]\n",
    "\n",
    "while '.DS_Store' in train_file:\n",
    "    train_file.remove('.DS_Store')\n",
    "while '.DS_Store' in test_file:\n",
    "    test_file.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fcbe6cf-497b-4d2c-8212-f8314848eeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████▎     | 28/58 [01:07<01:12,  2.42s/it]\n",
      "  2%|▏           | 1/58 [00:02<02:03,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.33322516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▍           | 2/58 [00:04<01:59,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.52423525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌           | 3/58 [00:06<01:56,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.4966679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▊           | 4/58 [00:08<01:53,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.56088614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█           | 5/58 [00:10<01:51,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.52665424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█▏          | 6/58 [00:12<01:50,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.53610593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▍          | 7/58 [00:14<01:47,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5415203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▋          | 8/58 [00:16<01:44,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5458075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▊          | 9/58 [00:18<01:42,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.545138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▉         | 10/58 [00:20<01:39,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5498241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██         | 11/58 [00:23<01:38,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5514432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▎        | 12/58 [00:25<01:35,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5787468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▍        | 13/58 [00:27<01:33,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.562542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▋        | 14/58 [00:29<01:31,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.56445587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▊        | 15/58 [00:31<01:29,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5884948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███        | 16/58 [00:33<01:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.6033659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███▏       | 17/58 [00:35<01:25,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.60115445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▍       | 18/58 [00:37<01:23,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.585781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▌       | 19/58 [00:39<01:21,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.58573145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▊       | 20/58 [00:41<01:18,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5837762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▉       | 21/58 [00:43<01:17,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5780293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████▏      | 22/58 [00:46<01:15,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.57654953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████▎      | 23/58 [00:48<01:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.57568693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▌      | 24/58 [00:50<01:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.57740515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▋      | 25/58 [00:52<01:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5772779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▉      | 26/58 [00:54<01:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.5761111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████      | 27/58 [00:56<01:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.57683384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████▎     | 28/58 [00:58<01:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.57346404\n",
      "Mean IoU = 0.5785345\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "batch_size = 2\n",
    "test_datagen = generate_brats_batch(file_pattern, contrasts, batch_size = batch_size, patient_ids = test_file, crop_size= (128,128,128)) # first iteration\n",
    "\n",
    "# predict on generator\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)\n",
    "i = 0\n",
    "\n",
    "while i < len(test_file)//batch_size:\n",
    "    test_image_batch, test_mask_batch = test_datagen.__next__()\n",
    "    \n",
    "    test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "    test_pred_batch = my_model.predict(test_image_batch)\n",
    "    test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "    IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "    i += 1\n",
    "    print(\"Mean IoU =\", IOU_keras.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b002a45-13f1-4b40-ab76-83b9d33977cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b53cd-363a-4e56-966b-8c52b0b072d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
